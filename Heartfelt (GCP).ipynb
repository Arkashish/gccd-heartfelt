{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ_-Ham-5AHV"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "### **Professional Machine Learning Engineer Certification**\n",
    "\n",
    "The Professional Machine Learning Engineer Certification by Google Cloud was released to the public on October 15th, 2020. According to the official [examination page](https://cloud.google.com/certification/machine-learning-engineer):\n",
    "\n",
    "> A Professional Machine Learning Engineer designs, builds, and productionizes ML models to solve business challenges using Google Cloud technologies and knowledge of proven ML models and techniques. The ML Engineer is proficient in all aspects of model architecture, data pipeline interaction, and metrics interpretation and needs familiarity with application development, infrastructure management, data engineering, and security.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gW4kTeWGYgc"
   },
   "source": [
    "In this session, we'll be looking at the following:\n",
    "\n",
    "1. The nature of an exam question and how it can be tackled.\n",
    "2. Building an appropriate solution with the identified tools.\n",
    "3. Deploying the produced solution on Google Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B82L4YGz9mjG"
   },
   "source": [
    "# The Problem\n",
    "\n",
    "Today, we'll be building an AI-powered model capable of assigning one of five emojis to a given comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4MQzFiS6IPn"
   },
   "source": [
    "## The Problem Statement\n",
    "\n",
    "Let's set the stage with an exam-level question:\n",
    "\n",
    "*Heartfelt is a modern startup working on a new website comment system. It uses AI to generate one of five emotions from each comment (Happy, Funny, Scared, Angry, Sad). It then shows the number of each of the five reactions above the comment section.*\n",
    "\n",
    "```\n",
    "  21341 ðŸ˜ƒ     21 ðŸ˜‚     0 ðŸ˜¨     2 ðŸ˜      5 ðŸ˜­\n",
    "_____________________________________________________\n",
    "\n",
    "Sathish\n",
    "  This honestly made my day!                                      ðŸ˜ƒ\n",
    "\n",
    "Pranay\n",
    "  We really need more good news in the world, like this...        ðŸ˜ƒ\n",
    "\n",
    "Maitreyi\n",
    "  Awesome!                                                        ðŸ˜ƒ\n",
    "```\n",
    "\n",
    "*They have obtained and labeled a large number of comments from their existing non-AI based system and are looking to upgrade to the new solution within a year. Their in-house ML engineers have designed a proprietary model, and apart from using the cloud for training and deploying, they also want to be able to fine-tune it for accuracy.*\n",
    "\n",
    "*What is the best way to build, tune, and deploy the model?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrjQ3OC6Bycg"
   },
   "source": [
    "## The Proposed Solution\n",
    "\n",
    "1. Files containing the labelled (Comment, Category) pairs are stored in a **Google Cloud Storage** bucket.\n",
    "2. **AI Platform Notebooks** will be used to access and process the data stored in the GCS bucket, rapidly prototype to find the best architecture, and train the model on a small portion of the dataset.\n",
    "3. **AI Platform Jobs** will be used to train the identified model architecture on the entirety of the dataset, performing hyperparameter tuning along the way. The trained model will be versioned and stored in a GCS bucket.\n",
    "4. **AI Platform Prediction** will be used to deploy the stored model. It allows for versioning, phased rollouts, and easy access to the model with REST API calls.\n",
    "5. **Google Cloud Storage** hosts the trained model, which is accessed by AI Platform Prediction.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Kq4pW5EC4vj"
   },
   "source": [
    "# The Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jSXUGF2IM2z"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2IAgkM0RIRgb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oM76hDsDXiH"
   },
   "source": [
    "## Obtaining and Processing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11ROuofz_NmN"
   },
   "source": [
    "The dataset used here was entirely created by me. Let us take a moment to understand it.\n",
    "\n",
    "There are 200 sentence-label pairs, 40 in each of 5 categories- Happy (0), Funny (1), Scared (2), Angry (3), and Sad (4). The first thing we need to do is define a method that converts between these numbers and the emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4b5rUYGhNltn"
   },
   "outputs": [],
   "source": [
    "list_of_emojis = ['ðŸ˜ƒ','ðŸ˜‚','ðŸ˜¨','ðŸ˜ ','ðŸ˜­']\n",
    "\n",
    "def label_to_emoji(label):\n",
    "  return list_of_emojis[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0aMTZ-S__gy"
   },
   "source": [
    "Now, we open the dataset and create two lists- one to store the strings (data) and the other to store the labels (labels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QXwuZvm8_eQF"
   },
   "outputs": [],
   "source": [
    "# The next cell is only for use on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Efij8yH6_d3E"
   },
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "\n",
    "def prepare_data(filename):\n",
    "\n",
    "  data = []\n",
    "  labels = []\n",
    "    \n",
    "  if filename.startswith('gs://'):\n",
    "    fs = gcsfs.GCSFileSystem(project='durable-will-291417')\n",
    "    with fs.open(filename, \"rt\", encoding=\"ascii\") as my_dataset:\n",
    "        \n",
    "      reader = csv.reader(my_dataset, delimiter=',')\n",
    "      for row in reader:\n",
    "        data.append(row[0])\n",
    "        labels.append(int(row[1]))\n",
    "        \n",
    "  else:\n",
    "    with open(filename) as my_dataset:\n",
    "\n",
    "      reader = csv.reader(my_dataset, delimiter=',')\n",
    "      for row in reader:\n",
    "        data.append(row[0])\n",
    "        labels.append(int(row[1]))\n",
    "\n",
    "  return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YarUFFTo_fGX"
   },
   "outputs": [],
   "source": [
    "# The next cell is only for use on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fk5jK6C5JCBc"
   },
   "outputs": [],
   "source": [
    "# def prepare_data(filename):\n",
    "#   data = []\n",
    "#   labels = []\n",
    "\n",
    "#   with open(filename) as my_dataset:\n",
    "\n",
    "#     reader = csv.reader(my_dataset, delimiter=',')\n",
    "\n",
    "#     for row in reader:\n",
    "\n",
    "#       data.append(row[0])\n",
    "#       labels.append(int(row[1]))\n",
    "\n",
    "#   return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ov51s80Sh6Df"
   },
   "outputs": [],
   "source": [
    "data, labels = prepare_data('heartfelt_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Kr-pQ3aAPxZ"
   },
   "source": [
    "The next block of code is used to shuffle these pairs while maintaining the order between them. We first split the data into 2 buckets - 150 in Train and 50 in Test. We then print 10 examples of both train and test data, along with the emojified values of the labels that represent them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zL7c1tA7KpbJ"
   },
   "outputs": [],
   "source": [
    "def shuffle_data(data, labels):\n",
    "\n",
    "  X_train = []\n",
    "  Y_train = []\n",
    "  X_test = []\n",
    "  Y_test = []\n",
    "\n",
    "  list_to_shuffle = list(zip(data, labels))\n",
    "  random.shuffle(list_to_shuffle)\n",
    "\n",
    "  shuffled_data, shuffled_labels = zip(*list_to_shuffle)\n",
    "\n",
    "  X_train = shuffled_data[0:150]\n",
    "  Y_train = shuffled_labels[0:150]\n",
    "\n",
    "  X_test = shuffled_data[150:200]\n",
    "  Y_test = shuffled_labels[150:200]\n",
    "\n",
    "  return (X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8Hv8pk9hF7d",
    "outputId": "b2affbdf-04a1-417f-a9c4-832580eeb333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of training data:\n",
      "\n",
      "  Why do we stand for this? : ðŸ˜ \n",
      "  The new laws are going to harm our communities. : ðŸ˜¨\n",
      "  It hurts so bad! : ðŸ˜­\n",
      "  Fantastic. : ðŸ˜ƒ\n",
      "  Amazing! : ðŸ˜ƒ\n",
      "  Comedians need to be paid more! : ðŸ˜‚\n",
      "  Must watch! : ðŸ˜ƒ\n",
      "  That sound! : ðŸ˜‚\n",
      "  A serial killer? : ðŸ˜¨\n",
      "  This is difficult on all of us. : ðŸ˜­\n",
      "\n",
      "Examples of testing data:\n",
      "\n",
      "  Is it normal to be afraid after watching this? : ðŸ˜¨\n",
      "  Bring it on! : ðŸ˜ƒ\n",
      "  For sure! : ðŸ˜ƒ\n",
      "  Laughing so hard I'm practically crying! : ðŸ˜‚\n",
      "  We are so alike, man! : ðŸ˜ƒ\n",
      "  And that expression on his face, though! : ðŸ˜‚\n",
      "  Give me my five minutes back. : ðŸ˜ \n",
      "  If we progress at this rate, there's no stopping us! : ðŸ˜ƒ\n",
      "  That hurts! : ðŸ˜­\n",
      "  This is just proof that we are all mortal. : ðŸ˜­\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = shuffle_data(data, labels)\n",
    "\n",
    "print (\"Examples of training data:\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "  print (\"  {} : {}\".format(X_train[i], label_to_emoji(Y_train[i])))\n",
    "\n",
    "print ('')\n",
    "\n",
    "print (\"Examples of testing data:\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "  print (\"  {} : {}\".format(X_test[i], label_to_emoji(Y_test[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZ1Nr4GRAzy_"
   },
   "source": [
    "Sanity checks are essential. They help us ensure that the data was not corrupted during the ingestion and provide some insight into the data's nature. Let us look at how many samples we have in Train and Test, along with the lengths of the longest and shortest strings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPuXqdVKNLuh",
    "outputId": "7a0edf8b-e5e9-41f2-d64e-c30a70c8be53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set contains 150 examples with 150 labels\n",
      "\n",
      "The testing set contains 50 examples with 50 labels\n",
      "\n",
      "The length of the shortest sentence is 1\n",
      "\n",
      "The length of the longest sentence is 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"The training set contains {} examples with {} labels\\n\".format(len(X_train), len(Y_train)))\n",
    "print (\"The testing set contains {} examples with {} labels\\n\".format(len(X_test), len(Y_test)))\n",
    "\n",
    "min_len = len(min(X_train, key=len).split())\n",
    "print (\"The length of the shortest sentence is {}\\n\".format(min_len))\n",
    "\n",
    "max_len = len(max(X_train, key=len).split())\n",
    "print (\"The length of the longest sentence is {}\\n\".format(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89fs-5dGBsOz"
   },
   "source": [
    "Okay, perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wap1-mBS-KuM"
   },
   "source": [
    "## Constructing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1bgM1yzCTBg"
   },
   "source": [
    "\n",
    "The *model* is the algorithm we develop to be able to solve an AI problem. Without getting too deep into the architecture here, the basic idea is that we're building a model capable of learning the relationship between *embedded* forms of the sentences and their corresponding emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Hg7lue9QPxIH"
   },
   "outputs": [],
   "source": [
    "def Model():\n",
    "\n",
    "  model = keras.Sequential([keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1)),\n",
    "                            keras.layers.LSTM(units=128, return_sequences=True),\n",
    "                            keras.layers.Dropout(rate=0.5),\n",
    "                            keras.layers.LSTM(units=128, return_sequences=False),\n",
    "                            keras.layers.Dropout(rate=0.5),\n",
    "                            keras.layers.Dense(units=5),\n",
    "                            keras.layers.Activation(\"softmax\")])\n",
    "  \n",
    "  model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VC3pkrcTXBRc"
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP5NZP40-0-t"
   },
   "source": [
    "## Training Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEbCBqmPCjYZ"
   },
   "source": [
    "Before we can think about training this model on our data, there are some things we need to take care of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2bh29J1DfeU"
   },
   "source": [
    "One-hot encoding involves modifying the labels, such that each label is a vector containing precisely one 1 and all other 0s, uniquely corresponding to the emoji it represents. The one-hot encoded forms are as follows:\n",
    "\n",
    "0 becomes [1, 0, 0, 0, 0] (Happy)\n",
    "\n",
    "1 becomes [0, 1, 0, 0, 0] (Funny)\n",
    "\n",
    "2 becomes [0, 0, 1, 0, 0] (Scared)\n",
    "\n",
    "3 becomes [0, 0, 0, 1, 0] (Angry)\n",
    "\n",
    "4 becomes [0, 0, 0, 0, 1] (Sad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueMn3D6gDhs5"
   },
   "source": [
    "The method below one-hot encodes the training and test labels and shows you a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "024yTqowaAWD"
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(labels):\n",
    "  return tf.one_hot(labels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zu5Q6XuInupz",
    "outputId": "ea228288-3ee8-4c27-d6a4-f4db3760cad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is blatant injustice! : ðŸ˜  (The numeric value of this is 3)\n",
      "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "Y_train_oh = convert_to_one_hot(labels=Y_train)\n",
    "Y_test_oh = convert_to_one_hot(labels=Y_test)\n",
    "\n",
    "pos_to_test = 75\n",
    "print (\"{} : {} (The numeric value of this is {})\".format(X_train[pos_to_test], label_to_emoji(Y_train[pos_to_test]), Y_train[pos_to_test]))\n",
    "print (Y_train_oh[pos_to_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ez5bvOFQDrxR"
   },
   "source": [
    "A sentence embedding is a vector representation of the sentence, where it's translated into a unique combination of N numbers (dimensions). Here, we are using N=128 dimensions. Apart from uniquely identifying a sentence, these numbers also carry relative semantic meaning, which allows the model to learn relationships between similar sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8NqS2qHFF-V"
   },
   "source": [
    "For example, if the model was trained on the sentence \"I like puppies\" and the word \"adore\" never appeared anywhere in the training set, it can still learn to infer that \"I adore puppies\" should produce the same emoji. As for these embeddings themselves, you can create your own from massively large datasets or use one that someone else created. Here, we're going with the latter. The embeddings used here come from TensorFlow Hub (more in the references section below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvmwBRlpFVpx"
   },
   "source": [
    "Look at how the sentence \"I love you.\" becomes a vector of 128 numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HqLbOpvadnvH"
   },
   "outputs": [],
   "source": [
    "def load_hub_module():\n",
    "  embed = hub.load(\"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\")\n",
    "  return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2g5IpX9_mYrl",
    "outputId": "adbc8c4f-33f1-4356-c850-aaf2e98f722b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you.\n",
      "\n",
      "[[ 0.06720316 -0.05019467  0.19946459  0.12020276  0.14881054 -0.00456426\n",
      "  -0.05057551 -0.04841431 -0.19195782 -0.02451784 -0.12093704 -0.2852198\n",
      "  -0.00294066 -0.05971586  0.14719391  0.07701718  0.02095461 -0.06760143\n",
      "   0.15468313  0.01675761 -0.03760123 -0.05660797 -0.00736546  0.08649251\n",
      "  -0.08041847 -0.1563163   0.03294101  0.07168686 -0.11695939 -0.1823932\n",
      "  -0.08472857 -0.0987467  -0.03675023 -0.01732922  0.22283307 -0.05921975\n",
      "  -0.01329962 -0.05822768  0.06824754  0.17341426 -0.07891089 -0.23081318\n",
      "  -0.10878634 -0.30201977  0.0608683   0.08700971 -0.05933066 -0.13618678\n",
      "  -0.02547742  0.18084317  0.07031292 -0.11094392  0.04854394  0.15780668\n",
      "  -0.06359842 -0.09194843  0.02376433 -0.14330299  0.03715428 -0.06878028\n",
      "  -0.14734161  0.19417918  0.0823964   0.05661403 -0.05078657 -0.06345925\n",
      "   0.10933136  0.04545296  0.14868559 -0.03175765 -0.39383692  0.14416008\n",
      "   0.07267258 -0.11527298  0.09845851  0.01740749  0.08343427 -0.14131157\n",
      "   0.03251657  0.23407583  0.16797747  0.03399577 -0.057875   -0.10542976\n",
      "  -0.01186056 -0.05624991  0.01801045 -0.02148287  0.1361867   0.02048323\n",
      "  -0.10837713  0.00970503  0.06507829 -0.0664895   0.16917071 -0.03851476\n",
      "   0.13855007  0.06109535 -0.00296407 -0.01300511  0.09075141 -0.03050167\n",
      "   0.16900752 -0.12665273  0.08207355 -0.02063324 -0.16423716  0.12405533\n",
      "  -0.14883116  0.02858107 -0.11822073 -0.11193876 -0.02074423  0.03844061\n",
      "  -0.1346886  -0.05284637 -0.0035206  -0.14857209 -0.21723205  0.11980139\n",
      "   0.09087516  0.10499977 -0.0890507   0.29368913  0.17826816 -0.03604833\n",
      "  -0.05201548  0.09901257]]\n"
     ]
    }
   ],
   "source": [
    "embed = load_hub_module()\n",
    "print (\"I love you.\\n\\n{}\".format(embed([\"I love you.\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fG879H-FjH3"
   },
   "source": [
    "Now for the fun part! We pass the embedded training (and testing) data, the one-hot encoded training (and testing) labels, and specify a few other things- like how long we want the training to take place and the number of examples to train with each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "radmLsneY-g8"
   },
   "outputs": [],
   "source": [
    "def train_model(model, embed, X_train, Y_train_oh, X_test, Y_test_oh, num_epochs=100, batch_size=10, shuffle=True):\n",
    "  return model.fit(embed(X_train),\n",
    "                      Y_train_oh,\n",
    "                      epochs = num_epochs,\n",
    "                      batch_size = batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      validation_data=(embed(X_test), Y_test_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Bnooi-wmrwl",
    "outputId": "8711498b-8ff2-4f66-e440-119bd7051628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 1.6102 - accuracy: 0.1867 - val_loss: 1.6101 - val_accuracy: 0.1800\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.6053 - accuracy: 0.2867 - val_loss: 1.6096 - val_accuracy: 0.2400\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.6026 - accuracy: 0.2600 - val_loss: 1.6095 - val_accuracy: 0.1600\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.5993 - accuracy: 0.2533 - val_loss: 1.6078 - val_accuracy: 0.1800\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.5902 - accuracy: 0.3200 - val_loss: 1.6049 - val_accuracy: 0.2400\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.5780 - accuracy: 0.3333 - val_loss: 1.6005 - val_accuracy: 0.2200\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.5636 - accuracy: 0.3467 - val_loss: 1.5948 - val_accuracy: 0.2400\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.5300 - accuracy: 0.3733 - val_loss: 1.5792 - val_accuracy: 0.2400\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.4899 - accuracy: 0.4667 - val_loss: 1.5562 - val_accuracy: 0.2800\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.4305 - accuracy: 0.4467 - val_loss: 1.5199 - val_accuracy: 0.2800\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.3491 - accuracy: 0.5867 - val_loss: 1.4606 - val_accuracy: 0.3600\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.2379 - accuracy: 0.5933 - val_loss: 1.4375 - val_accuracy: 0.4600\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.1121 - accuracy: 0.6400 - val_loss: 1.4147 - val_accuracy: 0.4600\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.0355 - accuracy: 0.6933 - val_loss: 1.4076 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.9287 - accuracy: 0.7067 - val_loss: 1.3946 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.8221 - accuracy: 0.7600 - val_loss: 1.4003 - val_accuracy: 0.5400\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.7691 - accuracy: 0.7667 - val_loss: 1.3990 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.7228 - accuracy: 0.7933 - val_loss: 1.4154 - val_accuracy: 0.5400\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6463 - accuracy: 0.7800 - val_loss: 1.4583 - val_accuracy: 0.5400\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6714 - accuracy: 0.7467 - val_loss: 1.4362 - val_accuracy: 0.5600\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5646 - accuracy: 0.7800 - val_loss: 1.4577 - val_accuracy: 0.4800\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5580 - accuracy: 0.7933 - val_loss: 1.5203 - val_accuracy: 0.5200\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5011 - accuracy: 0.8267 - val_loss: 1.4557 - val_accuracy: 0.5200\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4722 - accuracy: 0.8467 - val_loss: 1.5479 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4425 - accuracy: 0.8400 - val_loss: 1.5155 - val_accuracy: 0.5400\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4417 - accuracy: 0.8467 - val_loss: 1.6059 - val_accuracy: 0.5200\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8533 - val_loss: 1.5916 - val_accuracy: 0.5400\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.3702 - accuracy: 0.8933 - val_loss: 1.6816 - val_accuracy: 0.5400\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3318 - accuracy: 0.9000 - val_loss: 1.6663 - val_accuracy: 0.5400\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3243 - accuracy: 0.8933 - val_loss: 1.6687 - val_accuracy: 0.5400\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2885 - accuracy: 0.9133 - val_loss: 1.7092 - val_accuracy: 0.5400\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2903 - accuracy: 0.8933 - val_loss: 1.7595 - val_accuracy: 0.5200\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2724 - accuracy: 0.9000 - val_loss: 1.7327 - val_accuracy: 0.5800\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2688 - accuracy: 0.9200 - val_loss: 1.8831 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2220 - accuracy: 0.9467 - val_loss: 1.8836 - val_accuracy: 0.5400\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1963 - accuracy: 0.9667 - val_loss: 1.9197 - val_accuracy: 0.5600\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2189 - accuracy: 0.9333 - val_loss: 1.9866 - val_accuracy: 0.5200\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1940 - accuracy: 0.9400 - val_loss: 2.1227 - val_accuracy: 0.5400\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1941 - accuracy: 0.9600 - val_loss: 2.0609 - val_accuracy: 0.5600\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1480 - accuracy: 0.9667 - val_loss: 2.0541 - val_accuracy: 0.5400\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1803 - accuracy: 0.9533 - val_loss: 2.1529 - val_accuracy: 0.5200\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1562 - accuracy: 0.9533 - val_loss: 2.2062 - val_accuracy: 0.5200\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1336 - accuracy: 0.9867 - val_loss: 2.1863 - val_accuracy: 0.5200\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1315 - accuracy: 0.9733 - val_loss: 2.2189 - val_accuracy: 0.5400\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1113 - accuracy: 0.9667 - val_loss: 2.2671 - val_accuracy: 0.5200\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1200 - accuracy: 0.9733 - val_loss: 2.3267 - val_accuracy: 0.5200\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1077 - accuracy: 0.9800 - val_loss: 2.3951 - val_accuracy: 0.5200\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1587 - accuracy: 0.9733 - val_loss: 2.1175 - val_accuracy: 0.5800\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1294 - accuracy: 0.9600 - val_loss: 2.2721 - val_accuracy: 0.5400\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0987 - accuracy: 0.9933 - val_loss: 2.3768 - val_accuracy: 0.5400\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1098 - accuracy: 0.9667 - val_loss: 2.3447 - val_accuracy: 0.5600\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1064 - accuracy: 0.9800 - val_loss: 2.3563 - val_accuracy: 0.5400\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1226 - accuracy: 0.9800 - val_loss: 2.4520 - val_accuracy: 0.5400\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0723 - accuracy: 0.9933 - val_loss: 2.4950 - val_accuracy: 0.5400\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1324 - accuracy: 0.9733 - val_loss: 2.5297 - val_accuracy: 0.5400\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0890 - accuracy: 0.9800 - val_loss: 2.5503 - val_accuracy: 0.5400\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0783 - accuracy: 0.9933 - val_loss: 2.5089 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1016 - accuracy: 0.9733 - val_loss: 2.6095 - val_accuracy: 0.5200\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0890 - accuracy: 0.9733 - val_loss: 2.5899 - val_accuracy: 0.5400\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0550 - accuracy: 0.9933 - val_loss: 2.5543 - val_accuracy: 0.5400\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0549 - accuracy: 0.9800 - val_loss: 2.5980 - val_accuracy: 0.5200\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0734 - accuracy: 0.9733 - val_loss: 2.6495 - val_accuracy: 0.5200\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 0.9933 - val_loss: 2.6174 - val_accuracy: 0.5400\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0562 - accuracy: 0.9933 - val_loss: 2.5833 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0776 - accuracy: 0.9800 - val_loss: 2.6323 - val_accuracy: 0.5200\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 0.9867 - val_loss: 2.6409 - val_accuracy: 0.5600\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0682 - accuracy: 0.9800 - val_loss: 2.5279 - val_accuracy: 0.5600\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 2.6460 - val_accuracy: 0.5200\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 0.9867 - val_loss: 2.7851 - val_accuracy: 0.5200\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 0.9867 - val_loss: 2.7871 - val_accuracy: 0.5200\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 0.9933 - val_loss: 2.7234 - val_accuracy: 0.5400\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 2.7921 - val_accuracy: 0.5400\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0621 - accuracy: 0.9867 - val_loss: 2.8862 - val_accuracy: 0.5400\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0409 - accuracy: 0.9933 - val_loss: 2.9148 - val_accuracy: 0.5400\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 2.8945 - val_accuracy: 0.5400\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 2.8301 - val_accuracy: 0.5600\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 2.8833 - val_accuracy: 0.5400\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 3.0501 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0345 - accuracy: 0.9933 - val_loss: 2.9938 - val_accuracy: 0.5200\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0420 - accuracy: 0.9933 - val_loss: 3.1103 - val_accuracy: 0.5200\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 3.0501 - val_accuracy: 0.5200\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 2.9876 - val_accuracy: 0.5200\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9933 - val_loss: 3.0591 - val_accuracy: 0.5200\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 3.0415 - val_accuracy: 0.5600\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 3.1156 - val_accuracy: 0.5600\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0370 - accuracy: 0.9867 - val_loss: 3.1661 - val_accuracy: 0.5200\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 3.3440 - val_accuracy: 0.5200\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 3.2330 - val_accuracy: 0.5200\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9867 - val_loss: 3.0693 - val_accuracy: 0.5200\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 3.1033 - val_accuracy: 0.5200\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 3.1861 - val_accuracy: 0.5200\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 3.2021 - val_accuracy: 0.5200\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 3.2689 - val_accuracy: 0.5200\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 3.2956 - val_accuracy: 0.5400\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 3.3012 - val_accuracy: 0.5400\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0366 - accuracy: 0.9867 - val_loss: 3.2712 - val_accuracy: 0.5400\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 3.4001 - val_accuracy: 0.5600\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 3.3304 - val_accuracy: 0.5600\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0329 - accuracy: 0.9867 - val_loss: 3.3789 - val_accuracy: 0.5400\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 3.4281 - val_accuracy: 0.5400\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, embed, X_train, Y_train_oh, X_test, Y_test_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRzVRmnqGDoU"
   },
   "source": [
    "If you don't understand this, don't worry. We're just having a look at how our model has been composed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODReUjmik-rA",
    "outputId": "58bba0c5-f1af-454a-8ff3-214a479c909d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (10, 1, 128)              0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (10, 1, 128)              131584    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (10, 1, 128)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (10, 128)                 131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (10, 128)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (10, 5)                   645       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (10, 5)                   0         \n",
      "=================================================================\n",
      "Total params: 263,813\n",
      "Trainable params: 263,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYZtCGEUGYRP"
   },
   "source": [
    "The plot shown here indicates how the model did in both Training, as well as in Validation. As you can see, the Validation Accuracy stopped growing after about 40-50% (though the Train Accuracy went up to 100%). Can you think of why? Hint: Lack of data on our end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "1dVWJb_S2mLr",
    "outputId": "d974d944-9bf3-4c57-df00-9b0ffea9414c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_train = history.history['accuracy']\n",
    "accuracy_val = history.history['val_accuracy']\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "\n",
    "epochs = range(1,101)\n",
    "\n",
    "plt.plot(epochs, accuracy_train, 'g', label='Training Accuracy')\n",
    "plt.plot(epochs, accuracy_val, 'b', label='Validation Accuracy')\n",
    "\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-m9b733F7GBn"
   },
   "source": [
    "## Predicting Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzVdIcNNGzvP"
   },
   "source": [
    "And we're done! Time to see if our model works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "97JQKpktgbPX"
   },
   "outputs": [],
   "source": [
    "def predict(list_of_input_sentences, mode='deploy'):\n",
    "\n",
    "  '''\n",
    "  Input: A list of sentences and a mode. 'Test' mode is used to simply generate \n",
    "         and print the string-emoji pairs to make sure everything works properly.\n",
    "         'Deploy' mode is used when we want to return a prediction for one\n",
    "         sentence at a time.\n",
    "\n",
    "  Task: Use the model built to make emoji predictions with the given sentences.\n",
    "  \n",
    "  '''\n",
    "\n",
    "  number_of_input_sentences = len(list_of_input_sentences)\n",
    "  embedded_list = embed(list_of_input_sentences)\n",
    "  prediction = model.predict(embedded_list)\n",
    "\n",
    "  if mode == 'test':\n",
    "    for i in range(number_of_input_sentences):\n",
    "      print (\"{} : {}\".format(list_of_input_sentences[i], label_to_emoji(tf.argmax(prediction[i]))))\n",
    "\n",
    "  elif mode == 'deploy':\n",
    "    return tf.argmax(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgKwxo_gG-qP"
   },
   "source": [
    "Here are some relatively straightforward sentences. If our model gets these too badly wrong, there might be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOYfhFXeqbig",
    "outputId": "0240f3f6-0aa6-4680-ad21-a1d7cdf4b49f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel like dancing today! : ðŸ˜ƒ\n",
      "Now THAT was funny! : ðŸ˜‚\n",
      "I am terrified. : ðŸ˜¨\n",
      "This isn't fair! : ðŸ˜ \n",
      "That hurts! : ðŸ˜­\n"
     ]
    }
   ],
   "source": [
    "predict([\"I feel like dancing today!\",\n",
    "         \"Now THAT was funny!\",\n",
    "         \"I am terrified.\",\n",
    "         \"This isn't fair!\",\n",
    "         \"That hurts!\"], mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coXpD3nNHOcY"
   },
   "source": [
    "Everything works fine. Now let's try to build out a mini-version of the comment system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vNhkuFVBnkoD"
   },
   "outputs": [],
   "source": [
    "class Comments:\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    self.comments = []\n",
    "    self.generated_emojis = []\n",
    "\n",
    "    self.num_happy = 0\n",
    "    self.num_laugh = 0\n",
    "    self.num_scared=0\n",
    "    self.num_angry=0\n",
    "    self.num_sad = 0\n",
    "\n",
    "  def input_sentences(self, list_of_input_sentences):\n",
    "\n",
    "    '''\n",
    "    Input: A list of comments.\n",
    "\n",
    "    Task: Generates emojis from the comments and saves the comment-emoji pairs.\n",
    "\n",
    "    '''\n",
    "\n",
    "    for sentence in list_of_input_sentences:\n",
    "\n",
    "      self.comments.append(sentence)\n",
    "\n",
    "      result = predict([sentence])\n",
    "\n",
    "      self.generated_emojis.append(label_to_emoji(result))\n",
    "\n",
    "      if result == 0:\n",
    "        self.num_happy = self.num_happy + 1\n",
    "      elif result == 1:\n",
    "        self.num_laugh = self.num_laugh + 1\n",
    "      elif result == 2:\n",
    "        self.num_scared = self.num_scared + 1\n",
    "      elif result == 3:\n",
    "        self.num_angry = self.num_angry + 1\n",
    "      elif result == 4:\n",
    "        self.num_sad = self.num_sad + 1\n",
    "\n",
    "  def display_comments(self):\n",
    "\n",
    "    '''\n",
    "    Task: Displays the entire comment system.\n",
    "    \n",
    "    '''\n",
    "      \n",
    "    print(\"{} ðŸ˜ƒ   {} ðŸ˜‚   {} ðŸ˜¨   {} ðŸ˜    {} ðŸ˜­\".format(self.num_happy, self.num_laugh, self.num_scared, self.num_angry, self.num_sad))\n",
    "    print (\"___________________________________\\n\\n\")\n",
    "\n",
    "    comment_emoji_pairs = zip(self.comments, self.generated_emojis)\n",
    "\n",
    "    for comment, emoji in comment_emoji_pairs:\n",
    "      print (\"{:<75}{:>1}\\n\".format(comment, emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "DjJDQLfwV1Fc"
   },
   "outputs": [],
   "source": [
    "comment_system = Comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51cNxKwyRg27",
    "outputId": "61236753-1326-41df-b83c-c294d064e38a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ðŸ˜ƒ   0 ðŸ˜‚   1 ðŸ˜¨   0 ðŸ˜    1 ðŸ˜­\n",
      "___________________________________\n",
      "\n",
      "\n",
      "The darkness is closing all around us.                                     ðŸ˜¨\n",
      "\n",
      "This is upsetting.                                                         ðŸ˜­\n",
      "\n",
      "Your smile is beautiful!                                                   ðŸ˜ƒ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment_system.input_sentences([\"The darkness is closing all around us.\",\n",
    "                                \"This is upsetting.\",\n",
    "                                \"Your smile is beautiful!\"])\n",
    "\n",
    "comment_system.display_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZ_j18kWVzmW",
    "outputId": "cd0613de-b948-4411-851f-b3a5d048b2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ðŸ˜ƒ   1 ðŸ˜‚   1 ðŸ˜¨   1 ðŸ˜    1 ðŸ˜­\n",
      "___________________________________\n",
      "\n",
      "\n",
      "The darkness is closing all around us.                                     ðŸ˜¨\n",
      "\n",
      "This is upsetting.                                                         ðŸ˜­\n",
      "\n",
      "Your smile is beautiful!                                                   ðŸ˜ƒ\n",
      "\n",
      "Are you mad?                                                               ðŸ˜ \n",
      "\n",
      "Hilarious!                                                                 ðŸ˜‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment_system.input_sentences([\"Are you mad?\",\n",
    "                                \"Hilarious!\"])\n",
    "\n",
    "comment_system.display_comments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMq88Q31CUg3"
   },
   "source": [
    "## Training With AI Platform Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOShqVp_Zz94"
   },
   "source": [
    "Now that we've built our model, and are happy with the performance, let's talk about training on AI Platform Jobs. Our notebook was used for rapid prototyping, and while we can (and have) produced a working model here, it may be better to train on Jobs.\n",
    "\n",
    "1. Jobs can be orchestrated within an AI pipeline.\n",
    "\n",
    "2. They run on temporarily allotted hardware, and unlike notebooks that are expensive to keep running, you're only charged for a job while it is running.\n",
    "\n",
    "3. You can use AI Platform's hyperparameter tuning service to find the best set of hyperparameters to use with your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcSDooiWdn6R"
   },
   "source": [
    "The approach is as follows:\n",
    "\n",
    "1. Train on a small dataset within your notebook (prototyping), and then with the entire dataset within Jobs. In this case, our dataset was anyway small, so this doesn't make a difference to us.\n",
    "\n",
    "2. When satisfied with the model code, build a Python package containing a task.py file (will be used only to read the hyperparameters passed as command-line arguments) and a model.py file (includes all the model code and program logic).\n",
    "\n",
    "3. Train the model with Jobs and save the model in Google Cloud Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEdeRS5J0k7C"
   },
   "source": [
    "First, we make a folder called *trainer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aceecdXyj8by"
   },
   "outputs": [],
   "source": [
    "%mkdir train\n",
    "%mkdir train/trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-AF7pZOkFCg"
   },
   "source": [
    "Let's start by writing an \\__ init __.py file. This is required to make the folder be treated as a Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnDOWbkjkEO0",
    "outputId": "11b604fd-5574-4a47-9f06-102121e846bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/trainer/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/trainer/__init__.py\n",
    "# This exists only as a formality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJQgwS8Pk081"
   },
   "source": [
    "Next, let's write the model.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbGK7PXKk0Cz",
    "outputId": "b96f0da9-63f9-438c-8308-9f54e83d5a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/trainer/model.py\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "list_of_emojis = ['ðŸ˜ƒ','ðŸ˜‚','ðŸ˜¨','ðŸ˜ ','ðŸ˜­']\n",
    "\n",
    "def label_to_emoji(label):\n",
    "  return list_of_emojis[label]\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# This block is only for use on GCP\n",
    "\n",
    "import gcsfs\n",
    "\n",
    "def prepare_data(filename):\n",
    "\n",
    "  data = []\n",
    "  labels = []\n",
    "    \n",
    "  if filename.startswith('gs://'):\n",
    "    fs = gcsfs.GCSFileSystem(project='durable-will-291417')\n",
    "    with fs.open(filename, \"rt\", encoding=\"ascii\") as my_dataset:\n",
    "        \n",
    "      reader = csv.reader(my_dataset, delimiter=',')\n",
    "      for row in reader:\n",
    "        data.append(row[0])\n",
    "        labels.append(int(row[1]))\n",
    "        \n",
    "  else:\n",
    "    with open(filename) as my_dataset:\n",
    "\n",
    "      reader = csv.reader(my_dataset, delimiter=',')\n",
    "      for row in reader:\n",
    "        data.append(row[0])\n",
    "        labels.append(int(row[1]))\n",
    "\n",
    "  return (data, labels)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# This block is only for use on Colab\n",
    "\n",
    "# def prepare_data(filename):\n",
    "#   data = []\n",
    "#   labels = []\n",
    "\n",
    "#   with open(filename) as my_dataset:\n",
    "\n",
    "#     reader = csv.reader(my_dataset, delimiter=',')\n",
    "\n",
    "#     for row in reader:\n",
    "\n",
    "#       data.append(row[0])\n",
    "#       labels.append(int(row[1]))\n",
    "\n",
    "#   return (data, labels)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def shuffle_data(data, labels):\n",
    "\n",
    "  X_train = []\n",
    "  Y_train = []\n",
    "  X_test = []\n",
    "  Y_test = []\n",
    "\n",
    "  list_to_shuffle = list(zip(data, labels))\n",
    "  random.shuffle(list_to_shuffle)\n",
    "\n",
    "  shuffled_data, shuffled_labels = zip(*list_to_shuffle)\n",
    "\n",
    "  X_train = shuffled_data[0:150]\n",
    "  Y_train = shuffled_labels[0:150]\n",
    "\n",
    "  X_test = shuffled_data[150:200]\n",
    "  Y_test = shuffled_labels[150:200]\n",
    "\n",
    "  return (X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "def Model():\n",
    "\n",
    "  model = keras.Sequential([keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1)),\n",
    "                            keras.layers.LSTM(units=128, return_sequences=True),\n",
    "                            keras.layers.Dropout(rate=0.5),\n",
    "                            keras.layers.LSTM(units=128, return_sequences=False),\n",
    "                            keras.layers.Dropout(rate=0.5),\n",
    "                            keras.layers.Dense(units=5),\n",
    "                            keras.layers.Activation(\"softmax\")])\n",
    "  \n",
    "  model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "def convert_to_one_hot(labels):\n",
    "  return tf.one_hot(labels, 5)\n",
    "\n",
    "def load_hub_module():\n",
    "  embed = hub.load(\"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\")\n",
    "  return embed\n",
    "\n",
    "def train_model(model,embed, X_train, Y_train_oh, X_test, Y_test_oh, num_epochs=100, batch_size=10, shuffle=True):\n",
    "  return model.fit(embed(X_train),\n",
    "                      Y_train_oh,\n",
    "                      epochs = num_epochs,\n",
    "                      batch_size = batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      validation_data=(embed(X_test), Y_test_oh))\n",
    "  \n",
    "# A helper method that uses all the above methods to create a model and save it\n",
    "# in a Cloud Bucket\n",
    "def train_and_save_model(dataset_location, output_dir):\n",
    "\n",
    "  data, labels = prepare_data(dataset_location)\n",
    "  print (\"Data loading successful.\\n\")\n",
    "\n",
    "  X_train, Y_train, X_test, Y_test = shuffle_data(data, labels)\n",
    "  print (\"Data shuffling and splitting successful.\\n\")\n",
    "\n",
    "  model = Model()\n",
    "  print (\"Model creation successful.\\n\")\n",
    "\n",
    "  embed = load_hub_module()\n",
    "  print (\"Hub module loading successful.\\n\")\n",
    "\n",
    "  Y_train_oh = convert_to_one_hot(labels=Y_train)\n",
    "  Y_test_oh = convert_to_one_hot(labels=Y_test)\n",
    "  print (\"One-hot encoding successful.\\n\")\n",
    "\n",
    "  print (\"Model training initiated.\\n\")\n",
    "  history = train_model(model, embed, X_train, Y_train_oh, X_test, Y_test_oh)\n",
    "  print (\"\\nModel training completed.\\n\")\n",
    "\n",
    "  savedmodel_dir = os.path.join(output_dir, 'savedmodel')\n",
    "  tf.saved_model.save(model, savedmodel_dir)\n",
    "  print (\"\\nModel saving completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXeGOJJnd2MJ"
   },
   "source": [
    "Lastly, let's write a task.py file that reads in command line arguments, trains the model, and then saves it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCTIU_-SZzWb",
    "outputId": "0eaed95b-ce27-4bde-c037-f961063cfb6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train/trainer/task.py\n",
    "import argparse\n",
    "\n",
    "from trainer import model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--data-file\",\n",
    "        help=\"Path to the dataset file.\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "      '--job-dir',\n",
    "      help='Location where the model should be saved.',\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    hparams = args.__dict__\n",
    "\n",
    "    model.train_and_save_model(hparams['data_file'], hparams['job_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyzgzsiNqWTY"
   },
   "source": [
    "With that done, let's move the dataset into a cloud bucket as Jobs cannot read from a locally stored file (make the file public as well). Then, let's make sure the above code works by running task.py with Jobs, locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "zHVvUmNIDDo2"
   },
   "outputs": [],
   "source": [
    "# The next cell is only for use on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "SKS0v6F_DDr9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://heartfelt_dataset.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  6.2 KiB/  6.2 KiB]                                                \n",
      "Operation completed over 1 objects/6.2 KiB.                                      \n",
      "Updated ACL on gs://gccd_heartfelt/heartfelt_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gsutil cp -r heartfelt_dataset.csv gs://gccd_heartfelt\n",
    "gsutil acl ch -u AllUsers:R gs://gccd_heartfelt/heartfelt_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "MUwlQzEqgDlZ"
   },
   "outputs": [],
   "source": [
    "# The next cell is only for use on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "AQt3HBKQVJP8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading successful.\n",
      "\n",
      "Data shuffling and splitting successful.\n",
      "\n",
      "Model creation successful.\n",
      "\n",
      "Hub module loading successful.\n",
      "\n",
      "One-hot encoding successful.\n",
      "\n",
      "Model training initiated.\n",
      "\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 86ms/step - loss: 1.6097 - accuracy: 0.1533 - val_loss: 1.6102 - val_accuracy: 0.1200\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.6052 - accuracy: 0.2933 - val_loss: 1.6109 - val_accuracy: 0.1400\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.6011 - accuracy: 0.3067 - val_loss: 1.6123 - val_accuracy: 0.1400\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.5957 - accuracy: 0.2933 - val_loss: 1.6127 - val_accuracy: 0.1400\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.5864 - accuracy: 0.3400 - val_loss: 1.6126 - val_accuracy: 0.1400\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.5783 - accuracy: 0.3200 - val_loss: 1.6130 - val_accuracy: 0.1400\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.5626 - accuracy: 0.3467 - val_loss: 1.6108 - val_accuracy: 0.1200\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.5333 - accuracy: 0.3800 - val_loss: 1.6081 - val_accuracy: 0.1400\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.4922 - accuracy: 0.4067 - val_loss: 1.6052 - val_accuracy: 0.1800\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.4319 - accuracy: 0.4733 - val_loss: 1.5874 - val_accuracy: 0.3400\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.3467 - accuracy: 0.5200 - val_loss: 1.5694 - val_accuracy: 0.3400\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.2487 - accuracy: 0.6200 - val_loss: 1.5347 - val_accuracy: 0.3200\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.1579 - accuracy: 0.6667 - val_loss: 1.5115 - val_accuracy: 0.3800\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0133 - accuracy: 0.6933 - val_loss: 1.4977 - val_accuracy: 0.3600\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.9130 - accuracy: 0.7067 - val_loss: 1.5157 - val_accuracy: 0.3600\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.8135 - accuracy: 0.7667 - val_loss: 1.5337 - val_accuracy: 0.3600\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.8516 - accuracy: 0.7467 - val_loss: 1.5557 - val_accuracy: 0.3400\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.7333 - accuracy: 0.7800 - val_loss: 1.6089 - val_accuracy: 0.3800\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6772 - accuracy: 0.7733 - val_loss: 1.5760 - val_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6271 - accuracy: 0.7867 - val_loss: 1.6092 - val_accuracy: 0.3800\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6324 - accuracy: 0.7867 - val_loss: 1.6110 - val_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5608 - accuracy: 0.8067 - val_loss: 1.5974 - val_accuracy: 0.4800\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.8667 - val_loss: 1.6635 - val_accuracy: 0.4800\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 0.8267 - val_loss: 1.6497 - val_accuracy: 0.4400\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4841 - accuracy: 0.8267 - val_loss: 1.7103 - val_accuracy: 0.4800\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4449 - accuracy: 0.8800 - val_loss: 1.7146 - val_accuracy: 0.4600\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8800 - val_loss: 1.7818 - val_accuracy: 0.4400\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4002 - accuracy: 0.8667 - val_loss: 1.8305 - val_accuracy: 0.4200\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3514 - accuracy: 0.9133 - val_loss: 1.8208 - val_accuracy: 0.4200\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3072 - accuracy: 0.9200 - val_loss: 1.8814 - val_accuracy: 0.4200\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2814 - accuracy: 0.9333 - val_loss: 1.9250 - val_accuracy: 0.4200\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2784 - accuracy: 0.9333 - val_loss: 1.9949 - val_accuracy: 0.4200\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2839 - accuracy: 0.9333 - val_loss: 1.9887 - val_accuracy: 0.4200\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2867 - accuracy: 0.9267 - val_loss: 2.0134 - val_accuracy: 0.4400\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.3217 - accuracy: 0.9067 - val_loss: 2.0490 - val_accuracy: 0.4200\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.2248 - accuracy: 0.9533 - val_loss: 2.0799 - val_accuracy: 0.4200\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2248 - accuracy: 0.9333 - val_loss: 2.1204 - val_accuracy: 0.4600\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2542 - accuracy: 0.9067 - val_loss: 2.1082 - val_accuracy: 0.4400\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1732 - accuracy: 0.9600 - val_loss: 2.1761 - val_accuracy: 0.4200\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1835 - accuracy: 0.9400 - val_loss: 2.1836 - val_accuracy: 0.4400\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1734 - accuracy: 0.9533 - val_loss: 2.1880 - val_accuracy: 0.4600\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1610 - accuracy: 0.9600 - val_loss: 2.1764 - val_accuracy: 0.4400\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1721 - accuracy: 0.9600 - val_loss: 2.2518 - val_accuracy: 0.4600\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.9733 - val_loss: 2.4091 - val_accuracy: 0.4600\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1562 - accuracy: 0.9467 - val_loss: 2.3729 - val_accuracy: 0.4400\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1431 - accuracy: 0.9733 - val_loss: 2.3756 - val_accuracy: 0.4400\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1303 - accuracy: 0.9667 - val_loss: 2.4927 - val_accuracy: 0.4600\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1173 - accuracy: 0.9667 - val_loss: 2.4514 - val_accuracy: 0.4400\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1335 - accuracy: 0.9600 - val_loss: 2.4544 - val_accuracy: 0.4400\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0985 - accuracy: 0.9800 - val_loss: 2.4785 - val_accuracy: 0.4600\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1023 - accuracy: 0.9800 - val_loss: 2.5314 - val_accuracy: 0.4400\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0951 - accuracy: 0.9733 - val_loss: 2.6253 - val_accuracy: 0.4400\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1024 - accuracy: 0.9867 - val_loss: 2.5346 - val_accuracy: 0.4600\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1006 - accuracy: 0.9867 - val_loss: 2.6901 - val_accuracy: 0.4400\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1096 - accuracy: 0.9733 - val_loss: 2.6742 - val_accuracy: 0.4400\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0784 - accuracy: 0.9867 - val_loss: 2.6015 - val_accuracy: 0.4600\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0962 - accuracy: 0.9800 - val_loss: 2.6867 - val_accuracy: 0.4400\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0748 - accuracy: 0.9933 - val_loss: 2.6841 - val_accuracy: 0.4600\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0804 - accuracy: 0.9800 - val_loss: 2.7312 - val_accuracy: 0.4800\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0713 - accuracy: 0.9867 - val_loss: 2.7290 - val_accuracy: 0.4600\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 2.7987 - val_accuracy: 0.4600\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0467 - accuracy: 0.9933 - val_loss: 2.8804 - val_accuracy: 0.4600\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0444 - accuracy: 0.9933 - val_loss: 2.9463 - val_accuracy: 0.4600\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0664 - accuracy: 0.9867 - val_loss: 2.9295 - val_accuracy: 0.4600\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0657 - accuracy: 0.9867 - val_loss: 3.0037 - val_accuracy: 0.4400\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 2.9879 - val_accuracy: 0.4400\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 2.9897 - val_accuracy: 0.4400\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0541 - accuracy: 0.9867 - val_loss: 3.0968 - val_accuracy: 0.4400\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 3.2509 - val_accuracy: 0.4400\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0780 - accuracy: 0.9800 - val_loss: 3.1112 - val_accuracy: 0.4400\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 3.0792 - val_accuracy: 0.4600\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0516 - accuracy: 0.9933 - val_loss: 3.2139 - val_accuracy: 0.4400\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 3.2688 - val_accuracy: 0.4400\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0455 - accuracy: 0.9867 - val_loss: 3.1745 - val_accuracy: 0.4600\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 3.2883 - val_accuracy: 0.4600\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9933 - val_loss: 3.3641 - val_accuracy: 0.4400\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0616 - accuracy: 0.9867 - val_loss: 3.2232 - val_accuracy: 0.4600\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 3.2604 - val_accuracy: 0.4600\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 3.2671 - val_accuracy: 0.4600\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0569 - accuracy: 0.9933 - val_loss: 3.2304 - val_accuracy: 0.4600\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0512 - accuracy: 0.9933 - val_loss: 3.3758 - val_accuracy: 0.4400\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0603 - accuracy: 0.9933 - val_loss: 3.4384 - val_accuracy: 0.4600\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0958 - accuracy: 0.9533 - val_loss: 3.5572 - val_accuracy: 0.4400\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 3.5310 - val_accuracy: 0.4400\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 3.4403 - val_accuracy: 0.4600\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0534 - accuracy: 0.9800 - val_loss: 3.3646 - val_accuracy: 0.4600\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0452 - accuracy: 0.9933 - val_loss: 3.4271 - val_accuracy: 0.4600\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9933 - val_loss: 3.4643 - val_accuracy: 0.4200\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 3.4706 - val_accuracy: 0.4600\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 3.5046 - val_accuracy: 0.4600\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 3.4920 - val_accuracy: 0.4600\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0488 - accuracy: 0.9867 - val_loss: 3.4862 - val_accuracy: 0.4600\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 0.9867 - val_loss: 3.5956 - val_accuracy: 0.4600\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 3.6318 - val_accuracy: 0.4600\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 3.6034 - val_accuracy: 0.4600\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 3.6836 - val_accuracy: 0.4600\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9867 - val_loss: 3.6849 - val_accuracy: 0.4400\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0449 - accuracy: 0.9733 - val_loss: 3.5042 - val_accuracy: 0.4600\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 3.4477 - val_accuracy: 0.4600\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 3.4903 - val_accuracy: 0.4600\n",
      "\n",
      "Model training completed.\n",
      "\n",
      "\n",
      "Model saving completed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-19 13:16:12.388730: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200130000 Hz\n",
      "2021-01-19 13:16:12.389097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560d4cdd0970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-01-19 13:16:12.389137: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-01-19 13:16:12.389917: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2021-01-19 13:16:36.052223: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gcloud ai-platform local train \\\n",
    "    --job-dir '/home/jupyter/' \\\n",
    "    --module-name trainer.task \\\n",
    "    --package-path train/trainer/ \\\n",
    "    -- \\\n",
    "    --data-file='gs://gccd_heartfelt/heartfelt_dataset.csv' \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_4lzjGLgPEe"
   },
   "outputs": [],
   "source": [
    "# The next cell is only for use on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqipHolPqVbK",
    "outputId": "4aba0de8-835e-43d8-fb8e-0055d3307036"
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# cd train\n",
    "\n",
    "# python -m trainer.task \\\n",
    "#  --data-file='/content/heartfelt_dataset.csv' \\\n",
    "#  --job-dir='/content'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sR7aDJnOzJ_2"
   },
   "source": [
    "Now that we're sure it works, we can use AI Platform Jobs to perform the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SyeMUUXEbfx"
   },
   "outputs": [],
   "source": [
    "# The next cell is only for use on GCP\n",
    "# Increment the job number every time you run to avoid conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XK0FBWKXEaCp"
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# JOB_NAME=heartfelt_training_job_07\n",
    "\n",
    "# gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "#     --job-dir gs://gccd_heartfelt/$JOB_NAME \\\n",
    "#     --runtime-version 2.3 \\\n",
    "#     --python-version 3.7 \\\n",
    "#     --module-name trainer.task \\\n",
    "#     --package-path train/trainer \\\n",
    "#     --region us-central1 \\\n",
    "#     -- \\\n",
    "#     --data-file='gs://gccd_heartfelt/heartfelt_dataset.csv' \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7QXQzzdCz67"
   },
   "source": [
    "## Predicting With AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGDzLSKSz4Av"
   },
   "source": [
    "Now that our model has been trained and saved in a GCS bucket, we can make it accessible to the public (here, our company's website comment system). We will deploy the model to the AI Platform Prediction service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Rc5ijRKSKrb"
   },
   "outputs": [],
   "source": [
    "# The next cell is only for use on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds1ikKmkUkCk"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_NAME=heartfelt_comment_system\n",
    "REGION=us-central1\n",
    "\n",
    "gcloud ai-platform models create $MODEL_NAME --regions=$REGION\n",
    "    \n",
    "MODEL_PATH=gs://gccd_heartfelt/heartfelt_training_job_06/savedmodel/\n",
    "    \n",
    "gcloud ai-platform versions create v1 \\\n",
    "    --model $MODEL_NAME \\\n",
    "    --origin $MODEL_PATH \\\n",
    "    --runtime-version 2.3 \\\n",
    "    --python-version 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nu45DN5iUkgt"
   },
   "outputs": [],
   "source": [
    "# The next cell is only for use on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mFh7zfDVAYZ"
   },
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "\n",
    "PROJECT='durable-will-291417'\n",
    "MODEL_NAME='heartfelt_comment_system'\n",
    "VERSION_NAME='v1'\n",
    "service = googleapiclient.discovery.build('ml', 'v1', cache_discovery=False)\n",
    "\n",
    "name = 'projects/{}/models/{}/versions/{}'.format(PROJECT, MODEL_NAME, VERSION_NAME)\n",
    "\n",
    "list_of_inputs = [\"What a beautiful day!\", \"Disgusting!\", \"Mommy, I'm scared.\"]\n",
    "\n",
    "response = service.projects().predict(name=name,body={'instances': embed(list_of_inputs).numpy().tolist()}).execute()\n",
    "\n",
    "if 'error' in response:\n",
    "    raise RuntimeError(response['error'])\n",
    "else:\n",
    "    results = response['predictions']\n",
    "    for i, result in enumerate(results):\n",
    "        prediction = tf.argmax(result['activation'])\n",
    "        print (\"{} : {}\".format(list_of_inputs[i], label_to_emoji(prediction.numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koHgDzKW4rBi"
   },
   "source": [
    "*For brownie points, modify the Comments class above to use the AI Platform model to predict instead of the locally trained model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJPDdAHSIxub"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qg140FtKI2kW"
   },
   "source": [
    "I hope you found this session useful. As homework, here are some things you can do:\n",
    "\n",
    "1. Download this notebook and play around with the model. When does the model work well? When does it start failing? How does it handle ambiguous sentences?\n",
    "\n",
    "2. Create your own dataset (200-300 sentence-label pairs in total) and train the model on that. What kind of performance are you getting? Does using a more diverse range of words in your dataset help? Is the model able to accurately predict even when presented with a word outside your dataset? How long can the sentences be before things stop working? Alternatively, you can use someone else's dataset (check Kaggle).\n",
    "\n",
    "3. If you're familiar with these concepts, try improving the model's architecture. Check how adding/removing layers makes an impact on accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YU9S-3dn-STh"
   },
   "source": [
    "# Further Reading and Useful Links\n",
    "\n",
    "1. https://cloud.google.com/certification/machine-learning-engineer\n",
    "\n",
    "2. https://www.coursera.org/specializations/deep-learning\n",
    "\n",
    "3. https://www.coursera.org/professional-certificates/tensorflow-in-practice\n",
    "\n",
    "4. https://www.coursera.org/specializations/machine-learning-tensorflow-gcp\n",
    "\n",
    "5. https://www.coursera.org/specializations/advanced-machine-learning-tensorflow-gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMbDD3_xEi-L"
   },
   "source": [
    "# References\n",
    "\n",
    "1. This project was inspired by Coursera and DeepLearning.AI's [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning), where the project Emojify was done as a part of [Course 5 - Sequence Models](https://www.coursera.org/learn/nlp-sequence-models). While the idea is nearly identical, the implementation is notably different.\n",
    "\n",
    "2. I referred to *Getting started: Training and Prediction with TensorFlow Estimator* while building the GCP portions of this notebook. You can click [here](https://cloud.google.com/ai-platform/docs/getting-started-tensorflow-estimator?_ga=2.221022616.-1282698704.1600625468) to learn more.\n",
    "\n",
    "3. The trained word-embedding layer was pulled from TensorFlow Hub: *nnlm-en-dim128-with-normalization*. You can click [here](https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2) to see more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxUyGxx4xNZT"
   },
   "source": [
    "# License\n",
    "\n",
    "\n",
    "Copyright 2021, Viren Luke Radhakrishnan.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Wap1-mBS-KuM",
    "FP5NZP40-0-t",
    "-m9b733F7GBn",
    "TMq88Q31CUg3",
    "r7QXQzzdCz67"
   ],
   "name": "Heartfelt (Colab).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
